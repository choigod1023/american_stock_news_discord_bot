import aiohttp
import asyncio
from typing import List, Dict, Optional
import logging
import re

logger = logging.getLogger(__name__)

class NewsAPIClient:
    def __init__(self, community_api_url: str, news_api_url: str, page_size: int = 20, breaking_keywords: List[str] = None):
        self.community_api_url = community_api_url
        self.news_api_url = news_api_url
        self.page_size = page_size
        self.breaking_keywords = breaking_keywords or ['ì†ë³´', 'ê¸´ê¸‰', 'ì¤‘ìš”', 'íŠ¹ë³´', 'ê¸´ê¸‰ì†ë³´', 'íŠ¹ë³„ì†ë³´']
        self.session = None
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def fetch_news(self, page: int = 1) -> Optional[Dict]:
        """ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë‘ ê°œì˜ APIì—ì„œ ê°€ì ¸ì™€ì„œ ë³‘í•©í•©ë‹ˆë‹¤."""
        try:
            # ë‘ APIì—ì„œ ë°ì´í„°ë¥¼ ë³‘ë ¬ë¡œ ê°€ì ¸ì˜¤ê¸°
            community_data, news_data = await asyncio.gather(
                self._fetch_community_news(page),
                self._fetch_news_api(page),
                return_exceptions=True
            )
            
            # ê²°ê³¼ ë³‘í•©
            merged_posts = []
            
            # Community API ê²°ê³¼ ì²˜ë¦¬ (ë¦¬ìŠ¤íŠ¸ë¥¼ ë’¤ì—ì„œë¶€í„° ì½ì–´ì˜¤ê¸°)
            if isinstance(community_data, dict) and 'posts' in community_data:
                community_posts = community_data['posts']
                # ë¦¬ìŠ¤íŠ¸ë¥¼ ë’¤ì—ì„œë¶€í„° ì½ì–´ì„œ ìµœì‹  ë‰´ìŠ¤ê°€ ì•ì— ì˜¤ë„ë¡ í•¨
                for post in reversed(community_posts):
                    # Community APIì—ì„œ ì˜¨ ë‰´ìŠ¤ì„ì„ í‘œì‹œ
                    post['_source_api'] = 'community'
                    merged_posts.append(post)
                logger.info(f"Community API: {len(community_posts)}ê°œ ë‰´ìŠ¤ ìˆ˜ì‹ ")
            
            # News API ê²°ê³¼ ì²˜ë¦¬ (ë¦¬ìŠ¤íŠ¸ë¥¼ ë’¤ì—ì„œë¶€í„° ì½ì–´ì˜¤ê¸°)
            if isinstance(news_data, dict) and 'news_list' in news_data:
                news_posts = news_data['news_list']
                # ë¦¬ìŠ¤íŠ¸ë¥¼ ë’¤ì—ì„œë¶€í„° ì½ì–´ì„œ ìµœì‹  ë‰´ìŠ¤ê°€ ì•ì— ì˜¤ë„ë¡ í•¨
                for post in reversed(news_posts):
                    # News APIì—ì„œ ì˜¨ ë‰´ìŠ¤ì„ì„ í‘œì‹œ
                    post['_source_api'] = 'news'
                    merged_posts.append(post)
                logger.info(f"News API: {len(news_posts)}ê°œ ë‰´ìŠ¤ ìˆ˜ì‹ ")
            
            # ì¤‘ë³µ ì œê±° (ID ê¸°ì¤€) - ì´ë¯¸ ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬ëœ ìƒíƒœì—ì„œ ì¤‘ë³µ ì œê±°
            seen_ids = set()
            unique_posts = []
            for post in merged_posts:
                post_id = post.get('id')
                if post_id and post_id not in seen_ids:
                    seen_ids.add(post_id)
                    unique_posts.append(post)
            
            logger.info(f"ë³‘í•© ì™„ë£Œ: ì´ {len(unique_posts)}ê°œ ê³ ìœ  ë‰´ìŠ¤")
            
            return {
                'posts': unique_posts,
                'total_count': len(unique_posts),
                'page': page,
                'page_size': self.page_size,
                'from_cache': False
            }
                    
        except Exception as e:
            logger.error(f"ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
    
    async def _fetch_community_news(self, page: int = 1) -> Optional[Dict]:
        """Community APIì—ì„œ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        try:
            params = {
                'page': page,
                'page_size': self.page_size,
                'category': 'user_news',
                'sort': 'created_at_desc',
                'search': ''
            }
            
            async with self.session.get(self.community_api_url, params=params) as response:
                if response.status == 200:
                    return await response.json()
                else:
                    logger.error(f"Community API í˜¸ì¶œ ì‹¤íŒ¨: HTTP {response.status}")
                    return None
                    
        except Exception as e:
            logger.error(f"Community API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
    
    async def _fetch_news_api(self, page: int = 1) -> Optional[Dict]:
        """News APIì—ì„œ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        try:
            params = {
                'page': page,
                'page_size': self.page_size,
                'sort': 'created_at_desc'
            }
            
            async with self.session.get(self.news_api_url, params=params) as response:
                if response.status == 200:
                    return await response.json()
                else:
                    logger.error(f"News API í˜¸ì¶œ ì‹¤íŒ¨: HTTP {response.status}")
                    return None
                    
        except Exception as e:
            logger.error(f"News API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
    
    def get_news_list(self, data: Dict) -> List[Dict]:
        """API ì‘ë‹µì—ì„œ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        return data.get('posts', [])
    
    def is_breaking_news(self, news: Dict) -> bool:
        """ë‰´ìŠ¤ê°€ ì†ë³´ì¸ì§€ íŒë‹¨í•©ë‹ˆë‹¤."""
        title = news.get('title', '')
        content = news.get('content', '')
        community_tags = news.get('community_tags', [])
        tag_names = news.get('tag_names', [])  # News APIì˜ íƒœê·¸ êµ¬ì¡°
        
        # ì œëª©ì—ì„œ ì†ë³´ í‚¤ì›Œë“œ í™•ì¸
        for keyword in self.breaking_keywords:
            if keyword in title:
                return True
        
        # ë‚´ìš©ì—ì„œ ì†ë³´ í‚¤ì›Œë“œ í™•ì¸
        for keyword in self.breaking_keywords:
            if keyword in content:
                return True
        
        # ì»¤ë®¤ë‹ˆí‹° íƒœê·¸ì—ì„œ ì†ë³´ ê´€ë ¨ íƒœê·¸ í™•ì¸ (Community API)
        for tag in community_tags:
            if any(keyword in tag for keyword in self.breaking_keywords):
                return True
        
        # íƒœê·¸ ì´ë¦„ì—ì„œ ì†ë³´ ê´€ë ¨ íƒœê·¸ í™•ì¸ (News API)
        for tag in tag_names:
            if any(keyword in tag for keyword in self.breaking_keywords):
                return True
        
        # íŠ¹ì • íŒ¨í„´ í™•ì¸ (ì˜ˆ: [ì†ë³´], [ê¸´ê¸‰] ë“±)
        breaking_patterns = [
            r'\[ì†ë³´\]', r'\[ê¸´ê¸‰\]', r'\[ì¤‘ìš”\]', r'\[íŠ¹ë³´\]',
            r'ì†ë³´:', r'ê¸´ê¸‰:', r'ì¤‘ìš”:', r'íŠ¹ë³´:',
            r'ğŸš¨', r'âš¡', r'ğŸ”¥'
        ]
        
        for pattern in breaking_patterns:
            if re.search(pattern, title, re.IGNORECASE) or re.search(pattern, content, re.IGNORECASE):
                return True
        
        return False
    
    def is_important_news(self, news: Dict, threshold: int = 5, from_news_api: bool = False) -> bool:
        """ë‰´ìŠ¤ê°€ ì¤‘ìš”í•œì§€ íŒë‹¨í•©ë‹ˆë‹¤ (ì†ë³´ê°€ ì•„ë‹Œ ê²½ìš°)."""
        # ì†ë³´ëŠ” í•­ìƒ ì¤‘ìš”í•˜ë¯€ë¡œ ë³„ë„ ì²˜ë¦¬
        if self.is_breaking_news(news):
            return True
        
        # News APIì—ì„œ ì˜¨ ë‰´ìŠ¤ë§Œ ì¤‘ìš” ë‰´ìŠ¤ êµ¬ë¶„ ì ìš©
        if not from_news_api:
            return False
            
        like_count = news.get('like_stats', {}).get('like_count', 0)
        view_count = news.get('view_count', 0)
        
        # ì¢‹ì•„ìš” ìˆ˜ê°€ ì„ê³„ê°’ì„ ë„˜ê±°ë‚˜ ì¡°íšŒìˆ˜ê°€ ë†’ì€ ê²½ìš° ì¤‘ìš” ë‰´ìŠ¤ë¡œ íŒë‹¨
        return like_count >= threshold or view_count >= 100
    
    def get_news_type(self, news: Dict) -> str:
        """ë‰´ìŠ¤ íƒ€ì…ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if self.is_breaking_news(news):
            return "ì†ë³´"
        elif self.is_important_news(news):
            return "ì¤‘ìš”"
        else:
            return "ì¼ë°˜"
    
    def format_news_url(self, news_id: str, source_api: str = None) -> str:
        """ë‰´ìŠ¤ ìƒì„¸ í˜ì´ì§€ URLì„ ìƒì„±í•©ë‹ˆë‹¤."""
        if source_api == 'news':
            # News APIì˜ ê²½ìš° news ë¼ìš°í„° ì‚¬ìš©
            return f"https://saveticker.com/news/{news_id}"
        else:
            # Community APIì˜ ê²½ìš° community ë¼ìš°í„° ì‚¬ìš©
            return f"https://saveticker.com/community/{news_id}"